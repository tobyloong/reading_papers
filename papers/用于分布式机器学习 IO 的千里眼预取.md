# 用于分布式机器学习 I/O 的千里眼预取

### 摘要

I/O 正在成为机器学习训练的主要瓶颈，尤其是在分布式环境中。事实上，在大规模情况下，I/O 占用了多达 85% 的训练时间。解决此 I/O 瓶颈需要仔细优化，因为系统之间的最佳数据摄取管道不同，并且需要在访问本地存储、外部文件系统和远程节点之间取得微妙的平衡。我们介绍了 NoPFS，这是一种机器学习 I/O 中间件，它为 I/O 瓶颈提供了可扩展、灵活且易于使用的解决方案。NoPFS使用千里眼：给定生成随机访问模式的种子，以便使用SGD进行训练，它可以准确预测何时何地访问样本。我们将其与访问模式分析和性能模型相结合，以提供适应不同数据集和存储层次结构的分布式缓存策略。NoPFS 在 ImageNet-1k、ImageNet-22k 和 CosmoFlow 数据集上减少了 I/O 时间，并将端到端训练提高了多达 5.4×

### 简介

随着深度学习 （DL） 被更多领域采用，训练深度神经网络 （DNN） 在超级计算机上的工作负载越来越重要。鉴于培训成本高昂，至关重要的是，每个方面都应尽可能高效[66,74]。在优化训练[14]方面已经做了大量的工作，包括专用硬件[44,58]、编译器[21,29]、优化操作员原语[22,39]和通信基础设施[10,11,27,64,73]。从深度学习框架的角度来看，训练一个DNN涉及三个方面：执行DNN的计算;通信，用于在节点之间同步更新;以及 I/O，它为每个节点提供用于训练的数据和标签。关于优化训练的绝大多数工作都集中在计算和通信上。因此，训练中的性能瓶颈正在转向I/O [63,70]。事实上，我们发现，当在ImageNet [26]上大规模训练ResNet-50 [34]时，高达85%的运行时间是I/O开销，我们在其他数据集中也观察到类似的趋势。随着计算能力趋势的不断发展，机器学习加速器和数据集的样本数量达到数亿 [76] 到数十亿 [57]，大小达到 TB [3， 59， 67] 到 PB [2]，这种 I/O 瓶颈只会加剧。